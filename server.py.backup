"""
Mickey — Legal Intelligence Platform
Clean unified server — all modules under firm-based auth system.

Auth: session['firm_id'] + session['user_id'] (from auth blueprint)
Data: /opt/mickey/data/firms/{firm_id}/ per module
"""

# ── Config loader ──────────────────────────────────────────────
import os
from pathlib import Path

for _p in [
    Path("/opt/mickey/config.env"),
    Path(__file__).parent / "config.env",
]:
    if _p.exists():
        for _line in _p.read_text(encoding="utf-8").splitlines():
            _line = _line.strip()
            if _line and not _line.startswith("#") and "=" in _line:
                _k, _, _v = _line.partition("=")
                os.environ.setdefault(_k.strip(), _v.strip())
        break

import os, json, re, secrets, base64, hashlib, datetime, io, time, shutil, uuid
from pathlib import Path
from functools import wraps
from collections import defaultdict

from flask import Flask, request, jsonify, session, render_template, redirect, url_for, g
import anthropic

# ── App setup ──────────────────────────────────────────────────
app = Flask(__name__)

try:
    from auth.routes import auth_bp
    app.register_blueprint(auth_bp)
    print("  Auth module: loaded")
except Exception as e:
    print(f"  Auth module: not found ({e})")

try:
    from compliance.routes import compliance_bp
    app.register_blueprint(compliance_bp)
    print("  Compliance module: loaded")
except Exception as e:
    print(f"  Compliance module: not found ({e})")

app.secret_key = os.environ.get("MICKEY_SECRET", "CHANGE_ME_SET_MICKEY_SECRET_ENV_VAR")
if app.secret_key == "CHANGE_ME_SET_MICKEY_SECRET_ENV_VAR":
    print("\n  [WARNING] MICKEY_SECRET not set — generating random key for this session.\n")
    app.secret_key = secrets.token_hex(32)

app.config.update(
    SESSION_COOKIE_HTTPONLY  = True,
    SESSION_COOKIE_SAMESITE  = "Lax",
    SESSION_COOKIE_SECURE    = os.environ.get("MICKEY_HTTPS", "false").lower() == "true",
    PERMANENT_SESSION_LIFETIME = datetime.timedelta(hours=8),
)

# ── Base paths ─────────────────────────────────────────────────
BASE_PATH  = Path("/opt/mickey")
DATA_PATH  = BASE_PATH / "data"
FIRMS_PATH = DATA_PATH / "firms"

for p in [DATA_PATH, FIRMS_PATH, DATA_PATH / "uploads"]:
    p.mkdir(parents=True, exist_ok=True)

# ── API key handling ───────────────────────────────────────────
_KEY_SALT_FILE = BASE_PATH / "key.salt"
_API_KEY_FILE  = BASE_PATH / "api_key.enc"
_OAI_KEY_FILE  = BASE_PATH / "oai_key.enc"

def _fernet():
    try:
        from cryptography.fernet import Fernet
        from cryptography.hazmat.primitives import hashes
        from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC
    except ImportError:
        raise RuntimeError("Run: pip install cryptography")
    if not _KEY_SALT_FILE.exists():
        _KEY_SALT_FILE.write_bytes(secrets.token_bytes(32))
    salt = _KEY_SALT_FILE.read_bytes()
    kdf  = PBKDF2HMAC(algorithm=hashes.SHA256(), length=32, salt=salt, iterations=390000)
    key  = base64.urlsafe_b64encode(kdf.derive(app.secret_key.encode()))
    return Fernet(key)

def _encrypt(text): return _fernet().encrypt(text.encode()).decode()
def _decrypt(cipher): return _fernet().decrypt(cipher.encode()).decode()

def _read_key(path):
    if not path.exists(): return ""
    try:
        raw = path.read_text().strip()
        if not raw or not raw.startswith("gAAAAA"): return ""
        return _decrypt(raw)
    except: return ""

def _write_key(path, value):
    path.write_text(_encrypt(value.strip()))

def get_api_key():
    return os.environ.get("ANTHROPIC_API_KEY", "").strip() or _read_key(_API_KEY_FILE)

def get_oai_key():
    return os.environ.get("OPENAI_API_KEY", "").strip() or _read_key(_OAI_KEY_FILE)

def get_client():
    key = get_api_key()
    if not key: raise ValueError("Anthropic API key not configured.")
    return anthropic.Anthropic(api_key=key)

# ── Rate limiting ──────────────────────────────────────────────
RATE_LIMIT_CALLS_PER_HOUR = int(os.environ.get("MICKEY_RATE_LIMIT", "60"))
_rate_store = defaultdict(list)

def check_rate_limit(key):
    now = time.time()
    calls = [t for t in _rate_store[key] if now - t < 3600]
    _rate_store[key] = calls
    if len(calls) >= RATE_LIMIT_CALLS_PER_HOUR: return False
    _rate_store[key].append(now)
    return True

# ── Auth decorators ────────────────────────────────────────────
def login_required(f):
    @wraps(f)
    def dec(*a, **k):
        if not session.get("firm_id") or not session.get("user_id"):
            if request.is_json or request.path.startswith("/api/"):
                return jsonify({"error": "Authentication required"}), 401
            return redirect("/signin")
        session.modified = True
        return f(*a, **k)
    return dec

def admin_required(f):
    @wraps(f)
    def dec(*a, **k):
        if not session.get("firm_id"):
            return jsonify({"error": "Authentication required"}), 401
        if session.get("role") != "admin":
            return jsonify({"error": "Admin access required"}), 403
        session.modified = True
        return f(*a, **k)
    return dec

# ── CSRF ───────────────────────────────────────────────────────
def get_csrf_token():
    if "csrf_token" not in session:
        session["csrf_token"] = secrets.token_hex(32)
    return session["csrf_token"]

def verify_csrf(f):
    @wraps(f)
    def dec(*a, **k):
        if request.method in ("POST", "PUT", "DELETE", "PATCH"):
            token = request.headers.get("X-CSRF-Token", "")
            if not token or token != session.get("csrf_token", ""):
                return jsonify({"error": "CSRF validation failed"}), 403
        return f(*a, **k)
    return dec

# ── Session helpers ────────────────────────────────────────────
def get_firm_id():
    return session.get("firm_id", "")

def get_user_id():
    return session.get("user_id", "")

def get_username():
    """Bridge: returns email as username for rate limiting and logging."""
    return session.get("username") or session.get("email", "unknown")

def get_display_name():
    return session.get("display_name", session.get("email", "User"))

# ── Per-firm data paths ────────────────────────────────────────
def firm_path(firm_id: str) -> Path:
    p = FIRMS_PATH / firm_id
    p.mkdir(parents=True, exist_ok=True)
    return p

def user_data_path(firm_id: str, user_id: str) -> Path:
    p = firm_path(firm_id) / "users" / user_id
    for sub in ["workspace", "embeddings", "history", "templates",
                "obligations", "anonymised", "collections"]:
        (p / sub).mkdir(parents=True, exist_ok=True)
    return p

def shared_path(firm_id: str) -> Path:
    p = firm_path(firm_id) / "shared_library"
    (p / "embeddings").mkdir(parents=True, exist_ok=True)
    return p

# ── Embeddings ─────────────────────────────────────────────────
def get_embedding_openai(text: str) -> list:
    oai_key = get_oai_key()
    if not oai_key:
        return _hash_embedding(text)
    try:
        import openai
        client = openai.OpenAI(api_key=oai_key)
        resp = client.embeddings.create(model="text-embedding-3-small", input=text[:8000])
        return resp.data[0].embedding
    except Exception as e:
        print(f"  [Embedding fallback] {e}")
        return _hash_embedding(text)

def _hash_embedding(text: str) -> list:
    words = set(re.findall(r'\b[a-zA-Z]{3,}\b', text.lower()))
    vec = [0.0] * 256
    for w in words:
        idx = int(hashlib.md5(w.encode()).hexdigest(), 16) % 256
        vec[idx] += 1.0
    norm = sum(x*x for x in vec) ** 0.5
    return [x/norm for x in vec] if norm > 0 else vec

def cosine_sim(a, b):
    if not a or not b or len(a) != len(b): return 0.0
    dot = sum(x*y for x, y in zip(a, b))
    na = sum(x*x for x in a) ** 0.5
    nb = sum(x*x for x in b) ** 0.5
    return dot / (na * nb) if na * nb > 0 else 0.0

def save_embedding(emb_dir: Path, doc_id: str, emb: list):
    (emb_dir / f"{doc_id}.json").write_text(json.dumps(emb))

def load_embeddings(emb_dir: Path) -> dict:
    out = {}
    if not emb_dir.exists(): return out
    for f in emb_dir.glob("*.json"):
        try: out[f.stem] = json.loads(f.read_text())
        except: pass
    return out

# ── Shared library ─────────────────────────────────────────────
def load_shared_index(firm_id: str):
    f = shared_path(firm_id) / "index.json"
    if f.exists():
        try: return json.loads(f.read_text(encoding="utf-8"))
        except: return {}
    return {}

def save_shared_index(firm_id: str, idx: dict):
    (shared_path(firm_id) / "index.json").write_text(
        json.dumps(idx, ensure_ascii=False, indent=2), encoding="utf-8")

# ── Text extraction ────────────────────────────────────────────
def extract_bytes(data, filename):
    try:
        if filename.lower().endswith(".docx"):
            from docx import Document
            return "\n".join(p.text for p in Document(io.BytesIO(data)).paragraphs if p.text.strip())
        else:
            import pypdf
            return "\n".join(p.extract_text() or "" for p in pypdf.PdfReader(io.BytesIO(data)).pages).strip()
    except: return ""

def detect_ocr_needed(text: str, pages: int) -> bool:
    if pages == 0: return False
    return (len(text.strip()) / max(pages, 1)) < 80

def extract_bytes_with_meta(data: bytes, filename: str) -> dict:
    text = ""; pages = 0; ocr_needed = False
    try:
        if filename.lower().endswith(".docx"):
            from docx import Document as DocxDocument
            doc = DocxDocument(io.BytesIO(data))
            text = "\n".join(p.text for p in doc.paragraphs if p.text.strip())
            pages = max(1, len(text) // 3000)
        else:
            import pypdf
            reader = pypdf.PdfReader(io.BytesIO(data))
            pages = len(reader.pages)
            text = "\n".join(p.extract_text() or "" for p in reader.pages).strip()
            ocr_needed = detect_ocr_needed(text, pages)
    except: pass
    return {"text": text, "pages": pages, "ocr_needed": ocr_needed, "filename": filename}

# ── Context retrieval ──────────────────────────────────────────
def get_context(firm_id: str, user_id: str, query: str, max_chars=10000):
    query_words = set(w.lower() for w in re.findall(r'\b[a-zA-Z]{3,}\b', query))
    query_emb   = get_embedding_openai(query[:1000])
    results     = []

    sp = shared_path(firm_id)
    shared_embs = load_embeddings(sp / "embeddings")
    for doc_id, meta in load_shared_index(firm_id).items():
        tp = sp / f"{doc_id}.txt"
        if not tp.exists(): continue
        sem = cosine_sim(query_emb, shared_embs.get(doc_id, [])) * 10
        kw  = sum(2 for w in query_words if w in meta.get("name", "").lower())
        kw += sum(1 for w in query_words if w in meta.get("topic", "").lower())
        if sem + kw > 0.3:
            results.append((sem + kw, "library", doc_id, meta, tp))

    up = user_data_path(firm_id, user_id)
    user_embs = load_embeddings(up / "embeddings")
    for f in (up / "workspace").glob("*.txt"):
        did = f.stem
        try: text_preview = f.read_text(encoding="utf-8")[:200]
        except: continue
        sem = cosine_sim(query_emb, user_embs.get(did, [])) * 10
        kw  = sum(2 for w in query_words if w in did.lower().replace("_", " "))
        kw += sum(1 for w in query_words if w in text_preview.lower())
        if sem + kw > 0.3:
            results.append((sem + kw, "workspace", did, {"name": did.replace("_", " ")}, f))

    results.sort(key=lambda x: x[0], reverse=True)
    parts = []; total = 0; seen = set()
    for score, source, did, meta, path in results[:6]:
        if total >= max_chars or did in seen: continue
        seen.add(did)
        try:
            text = path.read_text(encoding="utf-8") if path.suffix == ".txt" else extract_bytes(path.read_bytes(), str(path))
            if not text: continue
            excerpt = text[:3000]
            lbl = {"library": "Legal Library", "workspace": "My Workspace"}.get(source, "")
            parts.append(f"[Source: {meta.get('name', did)} | {lbl}]\n{excerpt}")
            total += len(excerpt)
        except: pass
    return parts

# ── Claude helpers ─────────────────────────────────────────────
SKIP_FOLDERS = {
    "chatbestanden van microsoft teams", "microsoft copilot chat files",
    "microsoft teams chat files", "notebooks", "notitieblokken",
    "pictures", "recordings", "videos", "photos", "$recycle.bin",
    "system volume information", ".git", "__pycache__", "node_modules",
    "appdata", "windows", "program files", "program files (x86)"
}

def get_system(display_name):
    return f"""You are Mickey, a legal intelligence assistant for {display_name}.

You assist with any legal topic across any jurisdiction — Belgian law, EU law, English law, French law, Dutch law, Luxembourg law, US law, international law, and others.

Standards:
1. Cite articles precisely: "Art. 28(3) GDPR", "Art. 7:96 WVV", "s.90 Companies Act 2006"
2. Include jurisprudence: cite CJEU decisions, Belgian DPA rulings, EDPB guidelines, national court decisions
3. Distinguish clearly between settled law, developing case law, and your assessment
4. Use structured headers for longer answers
5. End every answer with "**Sources cited:**" listing all articles, cases and documents referenced
6. When documents from the knowledge base are provided, cite them by name and prioritise them
7. For Belgian law, always check both federal and regional competences where relevant"""

def docs_system(display_name: str) -> str:
    return f"""You are Mickey, a legal intelligence assistant for {display_name}.

You are operating in the Documents module. You analyse, draft, compare, summarise, translate, and anonymise legal documents with precision.

Standards:
1. Cite articles precisely: "Art. 28(3) GDPR", "Art. 7:96 WVV", "s.90 Companies Act 2006"
2. When a finding references a specific clause or article in the uploaded document, quote it briefly
3. Distinguish clearly: HIGH risk (must fix), MEDIUM risk (should address), LOW risk (minor)
4. Use structured output exactly as requested — the frontend parses your response
5. Belgian law: always check federal and regional competences where relevant
6. End legal analyses with "**Sources cited:**" listing all articles and cases referenced"""

def call_claude(display: str, prompt: str, system: str, max_tokens: int = 4000) -> tuple:
    try:
        client = get_client()
        resp = client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=max_tokens,
            system=system,
            messages=[{"role": "user", "content": prompt}]
        )
        answer = " ".join(b.text for b in resp.content if hasattr(b, "text") and b.text).strip()
        tokens = resp.usage.input_tokens + resp.usage.output_tokens
        return answer, tokens, None
    except ValueError as e:
        return None, 0, {"error": str(e), "need_key": True}
    except Exception as e:
        return None, 0, {"error": str(e)}

# ── Usage tracking ─────────────────────────────────────────────
USAGE_PATH = DATA_PATH / "usage"
USAGE_PATH.mkdir(exist_ok=True)

def log_usage(firm_id: str, user_id: str, event_type: str, tokens_used=0, detail=""):
    today = datetime.date.today().isoformat()
    f = USAGE_PATH / f"{firm_id}_{user_id}_{today}.jsonl"
    record = {
        "ts":     datetime.datetime.utcnow().isoformat(),
        "firm":   firm_id,
        "user":   user_id,
        "event":  event_type,
        "tokens": tokens_used,
        "detail": detail[:80]
    }
    with open(f, "a", encoding="utf-8") as fh:
        fh.write(json.dumps(record) + "\n")

# ══════════════════════════════════════════════════════════════
# ROUTES — Entry points
# ══════════════════════════════════════════════════════════════

@app.route("/")
def index():
    if session.get("firm_id"):
        return redirect("/app")
    return redirect("/signin")

@app.route("/app")
@login_required
def app_index():
    return render_template("index.html")

@app.route("/api/csrf")
@login_required
def csrf():
    return jsonify({"token": get_csrf_token()})

@app.route("/api/auth/status")
def auth_status():
    fid = session.get("firm_id")
    if fid:
        return jsonify({
            "logged_in":    True,
            "firm_id":      fid,
            "user_id":      session.get("user_id"),
            "username":     session.get("username"),
            "display_name": session.get("display_name"),
            "role":         session.get("role"),
            "firm_name":    session.get("firm_name"),
            "is_admin":     session.get("role") == "admin",
            "csrf_token":   get_csrf_token()
        })
    return jsonify({"logged_in": False})

@app.route("/health")
def health():
    return jsonify({"status": "ok", "timestamp": datetime.datetime.utcnow().isoformat()})

# ── API keys (admin only) ──────────────────────────────────────

@app.route("/api/key/set", methods=["POST"])
@admin_required
@verify_csrf
def set_key():
    d = request.get_json(force=True) or {}
    key = (d.get("key") or "").strip()
    if not key: return jsonify({"error": "No key provided"}), 400
    _write_key(_API_KEY_FILE, key)
    return jsonify({"ok": True})

@app.route("/api/key/set_oai", methods=["POST"])
@admin_required
@verify_csrf
def set_oai_key():
    d = request.get_json(force=True) or {}
    key = (d.get("key") or "").strip()
    if not key: return jsonify({"error": "No key provided"}), 400
    _write_key(_OAI_KEY_FILE, key)
    return jsonify({"ok": True})

@app.route("/api/key/status")
@login_required
def key_status():
    ak = get_api_key(); ok = get_oai_key()
    return jsonify({
        "anthropic":         bool(ak),
        "anthropic_masked":  ("sk-ant-..." + ak[-6:]) if ak else "",
        "openai":            bool(ok),
        "openai_masked":     ("sk-..." + ok[-6:]) if ok else ""
    })

# ── Legal Radar (Ask with web search) ─────────────────────────

@app.route("/api/ask", methods=["POST"])
@login_required
def ask():
    firm_id = get_firm_id(); user_id = get_user_id()
    rate_key = f"{firm_id}_{user_id}"
    if not check_rate_limit(rate_key):
        return jsonify({"error": f"Rate limit reached ({RATE_LIMIT_CALLS_PER_HOUR} calls/hour). Please wait."}), 429

    d        = request.get_json(force=True) or {}
    question = d.get("question", "")
    history  = d.get("history", [])
    use_web  = d.get("web_search", True)
    display  = get_display_name()

    ctx    = get_context(firm_id, user_id, question)
    prompt = ("Relevant documents:\n\n" + "\n\n---\n\n".join(ctx) + f"\n\n---\n\nQuestion: {question}") if ctx else question

    messages = [{"role": h["role"], "content": h["content"]}
                for h in history[-6:]
                if h.get("role") in ("user", "assistant") and h.get("content")]
    messages.append({"role": "user", "content": prompt})

    try:
        client = get_client()
        kwargs = dict(model="claude-sonnet-4-20250514", max_tokens=3000,
                      system=get_system(display), messages=messages)
        if use_web:
            kwargs["tools"] = [{"type": "web_search_20250305", "name": "web_search"}]
        resp   = client.messages.create(**kwargs)
        answer = " ".join(b.text for b in resp.content if hasattr(b, "text") and b.text).strip()
        tokens = resp.usage.input_tokens + resp.usage.output_tokens
        log_usage(firm_id, user_id, "ask", tokens, "discovery")
        return jsonify({"answer": answer})
    except ValueError as e:
        return jsonify({"error": str(e), "need_key": True}), 500
    except Exception as e:
        return jsonify({"error": str(e)}), 500

# ── Workspace ──────────────────────────────────────────────────

@app.route("/api/workspace", methods=["GET"])
@login_required
def get_workspace():
    up = user_data_path(get_firm_id(), get_user_id())
    docs = [{"id": f.stem, "name": f.stem.replace("_", " "), "size_kb": round(f.stat().st_size / 1024, 1)}
            for f in (up / "workspace").glob("*.txt")]
    return jsonify({"docs": sorted(docs, key=lambda x: x["name"])})

@app.route("/api/workspace/add", methods=["POST"])
@login_required
def add_workspace():
    firm_id = get_firm_id(); user_id = get_user_id()
    up   = user_data_path(firm_id, user_id)
    file = request.files.get("file")
    if not file: return jsonify({"error": "No file"}), 400
    text = extract_bytes(file.read(), file.filename)
    if not text: return jsonify({"error": "Could not extract text"}), 400
    stem = re.sub(r'[^\w\s\-]', '', Path(file.filename).stem)[:60].strip().replace(" ", "_")
    (up / "workspace" / f"{stem}.txt").write_text(text, encoding="utf-8")
    try:
        emb = get_embedding_openai(text[:3000])
        save_embedding(up / "embeddings", stem, emb)
    except: pass
    return jsonify({"ok": True, "id": stem})

@app.route("/api/workspace/delete", methods=["POST"])
@login_required
def delete_workspace():
    firm_id = get_firm_id(); user_id = get_user_id()
    up  = user_data_path(firm_id, user_id)
    did = (request.get_json(force=True) or {}).get("id", "")
    for ext in [".txt", ".json"]:
        for d in [up / "workspace", up / "embeddings"]:
            f = d / f"{did}{ext}"; f.exists() and f.unlink()
    return jsonify({"ok": True})

# ── Library (firm-shared) ──────────────────────────────────────

@app.route("/api/library", methods=["GET"])
@login_required
def get_library():
    firm_id = get_firm_id()
    idx  = load_shared_index(firm_id)
    docs = sorted([{**v, "id": k} for k, v in idx.items()],
                  key=lambda x: x.get("added_at", ""), reverse=True)
    return jsonify({"docs": docs})

@app.route("/api/library/add", methods=["POST"])
@admin_required
def add_library():
    firm_id = get_firm_id()
    file = request.files.get("file"); name = (request.form.get("name") or "").strip()
    if not file or not name: return jsonify({"error": "File and name required"}), 400
    text = extract_bytes(file.read(), file.filename)
    if not text: return jsonify({"error": "Could not extract text"}), 400
    did = secrets.token_hex(8)
    sp  = shared_path(firm_id)
    idx = load_shared_index(firm_id)
    idx[did] = {"name": name, "jurisdiction": (request.form.get("jurisdiction") or "").strip(),
                "topic": (request.form.get("topic") or "").strip(), "filename": file.filename,
                "added_by": get_user_id(), "added_at": datetime.datetime.now().isoformat(),
                "size_kb": round(len(text.encode()) / 1024, 1)}
    save_shared_index(firm_id, idx)
    (sp / f"{did}.txt").write_text(text, encoding="utf-8")
    try:
        emb = get_embedding_openai(text[:3000])
        save_embedding(sp / "embeddings", did, emb)
    except: pass
    log_usage(firm_id, get_user_id(), "add_library", 0, name[:40])
    return jsonify({"ok": True, "id": did})

@app.route("/api/library/delete", methods=["POST"])
@admin_required
def delete_library():
    firm_id = get_firm_id()
    did = (request.get_json(force=True) or {}).get("id", "")
    sp  = shared_path(firm_id)
    idx = load_shared_index(firm_id)
    if did in idx: del idx[did]
    save_shared_index(firm_id, idx)
    for ext in [".txt"]:
        f = sp / f"{did}{ext}"; f.exists() and f.unlink()
    emb = sp / "embeddings" / f"{did}.json"; emb.exists() and emb.unlink()
    return jsonify({"ok": True})

# ── Stats ──────────────────────────────────────────────────────

@app.route("/api/stats")
@login_required
def get_stats():
    firm_id = get_firm_id(); user_id = get_user_id()
    up = user_data_path(firm_id, user_id)
    return jsonify({
        "workspace": len(list((up / "workspace").glob("*.txt"))),
        "library":   len(load_shared_index(firm_id)),
    })

# ── Collections ────────────────────────────────────────────────

def _cols_path(firm_id, user_id):
    return user_data_path(firm_id, user_id) / "collections.json"

def load_collections(firm_id, user_id):
    f = _cols_path(firm_id, user_id)
    if f.exists():
        try: return json.loads(f.read_text(encoding="utf-8"))
        except: return {}
    return {}

def save_collections(firm_id, user_id, cols):
    _cols_path(firm_id, user_id).write_text(
        json.dumps(cols, indent=2, ensure_ascii=False), encoding="utf-8")

@app.route("/api/collections", methods=["GET"])
@login_required
def get_collections():
    return jsonify({"collections": load_collections(get_firm_id(), get_user_id())})

@app.route("/api/collections/create", methods=["POST"])
@login_required
def create_collection():
    firm_id = get_firm_id(); user_id = get_user_id()
    name = ((request.get_json(force=True) or {}).get("name") or "").strip()
    if not name: return jsonify({"error": "Name required"}), 400
    cols = load_collections(firm_id, user_id)
    cid  = secrets.token_hex(6)
    cols[cid] = {"name": name, "created": datetime.datetime.now().isoformat(), "items": []}
    save_collections(firm_id, user_id, cols)
    return jsonify({"ok": True, "id": cid})

@app.route("/api/collections/save_item", methods=["POST"])
@login_required
def save_to_collection():
    firm_id = get_firm_id(); user_id = get_user_id()
    d         = request.get_json(force=True) or {}
    cid       = d.get("collection_id", "")
    content   = (d.get("content") or "").strip()
    if not cid or not content: return jsonify({"error": "Collection and content required"}), 400
    cols = load_collections(firm_id, user_id)
    if cid not in cols: return jsonify({"error": "Collection not found"}), 404
    item = {
        "id":       secrets.token_hex(6),
        "title":    (d.get("title") or content[:60] + ("..." if len(content) > 60 else "")),
        "content":  content,
        "type":     d.get("type", "answer"),
        "source":   d.get("source", ""),
        "saved_at": datetime.datetime.now().isoformat()
    }
    cols[cid]["items"].append(item)
    save_collections(firm_id, user_id, cols)
    return jsonify({"ok": True})

@app.route("/api/collections/delete_item", methods=["POST"])
@login_required
def delete_collection_item():
    firm_id = get_firm_id(); user_id = get_user_id()
    d   = request.get_json(force=True) or {}
    cid = d.get("collection_id", ""); iid = d.get("item_id", "")
    cols = load_collections(firm_id, user_id)
    if cid not in cols: return jsonify({"error": "Not found"}), 404
    cols[cid]["items"] = [i for i in cols[cid]["items"] if i["id"] != iid]
    save_collections(firm_id, user_id, cols)
    return jsonify({"ok": True})

@app.route("/api/collections/delete", methods=["POST"])
@login_required
def delete_collection():
    firm_id = get_firm_id(); user_id = get_user_id()
    cid  = (request.get_json(force=True) or {}).get("collection_id", "")
    cols = load_collections(firm_id, user_id)
    if cid in cols: del cols[cid]
    save_collections(firm_id, user_id, cols)
    return jsonify({"ok": True})

@app.route("/api/collections/rename", methods=["POST"])
@login_required
def rename_collection():
    firm_id = get_firm_id(); user_id = get_user_id()
    d    = request.get_json(force=True) or {}
    cid  = d.get("collection_id", ""); name = (d.get("name") or "").strip()
    cols = load_collections(firm_id, user_id)
    if cid not in cols: return jsonify({"error": "Not found"}), 404
    cols[cid]["name"] = name
    save_collections(firm_id, user_id, cols)
    return jsonify({"ok": True})

# ── Info pages ─────────────────────────────────────────────────

@app.route("/api/info/<page>")
def info_page(page):
    pages = {"terms": _terms(), "privacy": _privacy(), "disclaimer": _disclaimer()}
    if page not in pages: return jsonify({"error": "Not found"}), 404
    return jsonify({"content": pages[page]})

def _terms():
    return """# Terms of Use

**Version 1.0 - February 2026**
**Operator:** Lex-IT, Belgium

## 1. Nature of the Platform

Mickey is an AI-assisted legal intelligence tool for authorised users. Mickey is not a law firm and does not provide legal advice. All outputs are AI-generated and must be reviewed by a qualified legal professional before reliance.

## 2. Authorised Use

Authorised users may use Mickey for legal research, document review, drafting support, translation, and knowledge management. Users may not share credentials, upload unauthorised confidential information, or attempt to circumvent security measures.

## 3. No Legal Advice

Mickey outputs do not constitute legal advice and do not create an attorney-client relationship."""

def _privacy():
    return """# Privacy Policy

**Version 1.0 - February 2026**

Provided in accordance with Articles 13-14 GDPR.

## 1. Controller

Lex-IT, Belgium

## 2. Data We Process

- Account data: name, email, encrypted password, creation date, role
- Usage data: timestamps, event types, token counts (no question content stored)
- Workspace documents: files you upload for knowledge retrieval
- Session tokens: valid 8 hours from last activity

## 3. Legal Basis

- Contract (Art. 6(1)(b) GDPR): authentication and service delivery
- Legitimate interest (Art. 6(1)(f) GDPR): usage monitoring, abuse prevention

## 4. Your Rights

Under GDPR you have rights of access (Art. 15), rectification (Art. 16), erasure (Art. 17), portability (Art. 20), and objection (Art. 21)."""

def _disclaimer():
    return """# AI Output Disclaimer

Mickey uses artificial intelligence to assist with legal research, document analysis, drafting, and translation. By using Mickey, you acknowledge that:

1. **Not legal advice.** Outputs do not constitute legal advice and do not create an attorney-client relationship.
2. **Verification required.** All outputs must be verified by a qualified legal professional before reliance.
3. **Accuracy not guaranteed.** AI models may produce errors or outdated analysis.
4. **No liability.** The operator accepts no liability for decisions made on the basis of Mickey outputs without appropriate professional review."""

# ══════════════════════════════════════════════════════════════
# CORPORATE HOUSEKEEPING
# ══════════════════════════════════════════════════════════════

def corp_path(firm_id: str) -> Path:
    p = firm_path(firm_id) / "corporate"
    p.mkdir(parents=True, exist_ok=True)
    return p

def corp_file(firm_id: str, entity_id: str) -> Path:
    safe = re.sub(r'[^\w\-]', '_', entity_id)[:60]
    return corp_path(firm_id) / f"{safe}.json"

def load_entity(firm_id: str, entity_id: str) -> dict:
    f = corp_file(firm_id, entity_id)
    if f.exists():
        try: return json.loads(f.read_text(encoding="utf-8"))
        except: return {}
    return {}

def save_entity(firm_id: str, entity_id: str, data: dict):
    corp_file(firm_id, entity_id).write_text(
        json.dumps(data, indent=2, ensure_ascii=False), encoding="utf-8")

def list_entities(firm_id: str) -> list:
    entities = []
    for f in corp_path(firm_id).glob("*.json"):
        try:
            d = json.loads(f.read_text(encoding="utf-8"))
            entities.append({
                "id":           f.stem,
                "name":         d.get("name", f.stem),
                "legal_form":   d.get("legal_form", ""),
                "jurisdiction": d.get("jurisdiction", ""),
                "status":       d.get("status", "active"),
                "updated_at":   d.get("updated_at", ""),
                "alert_count":  _count_alerts(d),
            })
        except: pass
    return sorted(entities, key=lambda x: x.get("name", "").lower())

def _count_alerts(entity: dict) -> int:
    count = 0; today = datetime.date.today()
    warn_date = today + datetime.timedelta(days=90)
    for d in entity.get("directors", []):
        if d.get("status") == "active" and d.get("mandate_end"):
            try:
                if datetime.date.fromisoformat(d["mandate_end"]) <= warn_date: count += 1
            except: pass
    for c in entity.get("compliance", []):
        if c.get("status") in ("pending", "overdue") and c.get("deadline"):
            try:
                if datetime.date.fromisoformat(c["deadline"]) < today: count += 1
            except: pass
    return count

def _add_history(entity: dict, event_type: str, description: str,
                 source: str = "", recorded_by: str = "") -> dict:
    entity.setdefault("history", []).insert(0, {
        "id":          secrets.token_hex(6),
        "ts":          datetime.datetime.now().isoformat(),
        "date":        datetime.date.today().isoformat(),
        "type":        event_type,
        "description": description,
        "source":      source,
        "recorded_by": recorded_by,
    })
    return entity

@app.route("/api/corp/entities", methods=["GET"])
@login_required
def corp_entities():
    return jsonify({"entities": list_entities(get_firm_id())})

@app.route("/api/corp/entity", methods=["GET"])
@login_required
def corp_get_entity():
    eid = request.args.get("id", "").strip()
    if not eid: return jsonify({"error": "id required"}), 400
    e = load_entity(get_firm_id(), eid)
    if not e: return jsonify({"error": "Entity not found"}), 404
    return jsonify({"entity": e})

@app.route("/api/corp/entity/create", methods=["POST"])
@login_required
@verify_csrf
def corp_create_entity():
    firm_id = get_firm_id()
    d = request.get_json(force=True) or {}
    name = (d.get("name") or "").strip()
    if not name: return jsonify({"error": "Name required"}), 400
    eid = secrets.token_hex(8); now = datetime.datetime.now().isoformat()
    entity = {
        "id": eid, "name": name,
        "legal_form": d.get("legal_form", ""), "jurisdiction": d.get("jurisdiction", ""),
        "status": d.get("status", "active"), "relationship": d.get("relationship", "subsidiary"),
        "created_at": now, "updated_at": now,
        "trade_name": d.get("trade_name", ""), "previous_names": d.get("previous_names", ""),
        "reg_number": d.get("reg_number", ""), "vat_number": d.get("vat_number", ""),
        "lei_code": d.get("lei_code", ""), "court_registration": d.get("court_registration", ""),
        "incorporation_date": d.get("incorporation_date", ""), "duration": d.get("duration", "Unlimited"),
        "financial_year_end": d.get("financial_year_end", "31 December"),
        "agm_date_rule": d.get("agm_date_rule", ""), "agm_notice_days": d.get("agm_notice_days", 30),
        "listed": d.get("listed", False),
        "registered_street": d.get("registered_street", ""), "registered_postcode": d.get("registered_postcode", ""),
        "registered_city": d.get("registered_city", ""), "registered_country": d.get("registered_country", ""),
        "share_capital": d.get("share_capital", ""), "capital_currency": d.get("capital_currency", "EUR"),
        "total_shares": d.get("total_shares", ""), "nominal_value": d.get("nominal_value", "No par value"),
        "auditor_firm": d.get("auditor_firm", ""), "auditor_partner": d.get("auditor_partner", ""),
        "auditor_mandate_end": d.get("auditor_mandate_end", ""),
        "board_model": d.get("board_model", "One-tier"), "min_directors": d.get("min_directors", 1),
        "max_directors": d.get("max_directors", 12), "signature_rule": d.get("signature_rule", "Joint"),
        "directors": [], "shareholders": [], "poas": [], "compliance": [],
        "history": [], "documents": [], "notes": d.get("notes", ""),
    }
    _add_history(entity, "other", f"Entity '{name}' created in Mickey",
                 recorded_by=get_user_id())
    save_entity(firm_id, eid, entity)
    log_usage(firm_id, get_user_id(), "corp_create", 0, name[:40])
    return jsonify({"ok": True, "id": eid})

@app.route("/api/corp/entity/update", methods=["POST"])
@login_required
@verify_csrf
def corp_update_entity():
    firm_id = get_firm_id()
    d = request.get_json(force=True) or {}
    eid = d.get("id", "").strip()
    if not eid: return jsonify({"error": "id required"}), 400
    entity = load_entity(firm_id, eid)
    if not entity: return jsonify({"error": "Entity not found"}), 404
    protected = {"id", "created_at", "directors", "shareholders", "poas", "compliance", "history", "documents"}
    for k, v in d.items():
        if k not in protected: entity[k] = v
    entity["updated_at"] = datetime.datetime.now().isoformat()
    _add_history(entity, "other", "Entity data updated", recorded_by=get_user_id())
    save_entity(firm_id, eid, entity)
    return jsonify({"ok": True})

@app.route("/api/corp/entity/delete", methods=["POST"])
@login_required
@verify_csrf
def corp_delete_entity():
    firm_id = get_firm_id()
    eid = (request.get_json(force=True) or {}).get("id", "").strip()
    if not eid: return jsonify({"error": "id required"}), 400
    f = corp_file(firm_id, eid)
    if f.exists(): f.unlink()
    return jsonify({"ok": True})

@app.route("/api/corp/director/add", methods=["POST"])
@login_required
@verify_csrf
def corp_add_director():
    firm_id = get_firm_id()
    d = request.get_json(force=True) or {}
    eid = d.get("entity_id", "").strip()
    entity = load_entity(firm_id, eid)
    if not entity: return jsonify({"error": "Entity not found"}), 404
    director = {
        "id": secrets.token_hex(6), "type": d.get("type", "natural_person"),
        "first_name": d.get("first_name", ""), "last_name": d.get("last_name", ""),
        "entity_name": d.get("entity_name", ""), "representative": d.get("representative", ""),
        "nationality": d.get("nationality", ""), "address": d.get("address", ""),
        "role": d.get("role", "Non-executive director"),
        "appointment_date": d.get("appointment_date", ""), "mandate_end": d.get("mandate_end", ""),
        "appointment_auth": d.get("appointment_auth", "AGM resolution"), "deed_ref": d.get("deed_ref", ""),
        "remuneration": d.get("remuneration", "Unpaid"), "signature_auth": d.get("signature_auth", "Joint"),
        "independent": d.get("independent", False), "status": "active",
        "notes": d.get("notes", ""), "added_at": datetime.datetime.now().isoformat(),
    }
    display_name = director["entity_name"] or f"{director['first_name']} {director['last_name']}".strip()
    entity.setdefault("directors", []).append(director)
    entity["updated_at"] = datetime.datetime.now().isoformat()
    _add_history(entity, "governance", f"Director added: {display_name} ({director['role']})",
                 source=director.get("deed_ref", ""), recorded_by=get_user_id())
    save_entity(firm_id, eid, entity)
    return jsonify({"ok": True, "id": director["id"]})

@app.route("/api/corp/director/update", methods=["POST"])
@login_required
@verify_csrf
def corp_update_director():
    firm_id = get_firm_id()
    d = request.get_json(force=True) or {}
    eid = d.get("entity_id", "").strip(); did = d.get("director_id", "").strip()
    entity = load_entity(firm_id, eid)
    if not entity: return jsonify({"error": "Entity not found"}), 404
    for i, dr in enumerate(entity.get("directors", [])):
        if dr["id"] == did:
            for k, v in d.items():
                if k not in ("entity_id", "director_id"): entity["directors"][i][k] = v
            break
    entity["updated_at"] = datetime.datetime.now().isoformat()
    _add_history(entity, "governance", f"Director record updated (id: {did})", recorded_by=get_user_id())
    save_entity(firm_id, eid, entity)
    return jsonify({"ok": True})

@app.route("/api/corp/director/end_mandate", methods=["POST"])
@login_required
@verify_csrf
def corp_end_mandate():
    firm_id = get_firm_id()
    d = request.get_json(force=True) or {}
    eid = d.get("entity_id", "").strip(); did = d.get("director_id", "").strip()
    reason = d.get("reason", "Mandate ended")
    entity = load_entity(firm_id, eid)
    if not entity: return jsonify({"error": "Entity not found"}), 404
    for dr in entity.get("directors", []):
        if dr["id"] == did:
            dr["status"] = "ended"; dr["end_date"] = datetime.date.today().isoformat(); dr["end_reason"] = reason
            name = dr.get("entity_name") or f"{dr.get('first_name', '')} {dr.get('last_name', '')}".strip()
            _add_history(entity, "governance", f"Director mandate ended: {name} — {reason}", recorded_by=get_user_id())
            break
    entity["updated_at"] = datetime.datetime.now().isoformat()
    save_entity(firm_id, eid, entity)
    return jsonify({"ok": True})

@app.route("/api/corp/shareholder/add", methods=["POST"])
@login_required
@verify_csrf
def corp_add_shareholder():
    firm_id = get_firm_id()
    d = request.get_json(force=True) or {}
    eid = d.get("entity_id", "").strip()
    entity = load_entity(firm_id, eid)
    if not entity: return jsonify({"error": "Entity not found"}), 404
    sh = {
        "id": secrets.token_hex(6), "name": d.get("name", ""),
        "type": d.get("type", "natural_person"), "nationality": d.get("nationality", ""),
        "address": d.get("address", ""), "shares": d.get("shares", 0),
        "pct": d.get("pct", 0.0), "share_class": d.get("share_class", "ordinary"),
        "acquisition_date": d.get("acquisition_date", ""), "acquisition_price": d.get("acquisition_price", ""),
        "ubo": d.get("ubo", False), "pledged": d.get("pledged", False),
        "pledge_details": d.get("pledge_details", ""), "notes": d.get("notes", ""),
        "added_at": datetime.datetime.now().isoformat(),
    }
    entity.setdefault("shareholders", []).append(sh)
    entity["updated_at"] = datetime.datetime.now().isoformat()
    _add_history(entity, "capital", f"Shareholder added: {sh['name']} ({sh['shares']} shares, {sh['pct']}%)",
                 recorded_by=get_user_id())
    save_entity(firm_id, eid, entity)
    return jsonify({"ok": True, "id": sh["id"]})

@app.route("/api/corp/shareholder/update", methods=["POST"])
@login_required
@verify_csrf
def corp_update_shareholder():
    firm_id = get_firm_id()
    d = request.get_json(force=True) or {}
    eid = d.get("entity_id", "").strip(); sid = d.get("shareholder_id", "").strip()
    entity = load_entity(firm_id, eid)
    if not entity: return jsonify({"error": "Entity not found"}), 404
    for i, sh in enumerate(entity.get("shareholders", [])):
        if sh["id"] == sid:
            for k, v in d.items():
                if k not in ("entity_id", "shareholder_id"): entity["shareholders"][i][k] = v
            break
    entity["updated_at"] = datetime.datetime.now().isoformat()
    _add_history(entity, "capital", f"Shareholder record updated (id: {sid})", recorded_by=get_user_id())
    save_entity(firm_id, eid, entity)
    return jsonify({"ok": True})

@app.route("/api/corp/poa/add", methods=["POST"])
@login_required
@verify_csrf
def corp_add_poa():
    firm_id = get_firm_id()
    d = request.get_json(force=True) or {}
    eid = d.get("entity_id", "").strip()
    entity = load_entity(firm_id, eid)
    if not entity: return jsonify({"error": "Entity not found"}), 404
    poa = {
        "id": secrets.token_hex(6), "grantee_name": d.get("grantee_name", ""),
        "grantee_address": d.get("grantee_address", ""), "granted_by": d.get("granted_by", ""),
        "grant_date": d.get("grant_date", ""), "duration": d.get("duration", "Unlimited"),
        "expiry_date": d.get("expiry_date", ""), "signature": d.get("signature", "Sole"),
        "status": "active", "powers": d.get("powers", []),
        "thresholds": d.get("thresholds", {}), "notes": d.get("notes", ""),
        "added_at": datetime.datetime.now().isoformat(),
    }
    entity.setdefault("poas", []).append(poa)
    entity["updated_at"] = datetime.datetime.now().isoformat()
    _add_history(entity, "governance", f"Power of attorney granted to {poa['grantee_name']}",
                 source=poa.get("granted_by", ""), recorded_by=get_user_id())
    save_entity(firm_id, eid, entity)
    return jsonify({"ok": True, "id": poa["id"]})

@app.route("/api/corp/poa/revoke", methods=["POST"])
@login_required
@verify_csrf
def corp_revoke_poa():
    firm_id = get_firm_id()
    d = request.get_json(force=True) or {}
    eid = d.get("entity_id", "").strip(); pid = d.get("poa_id", "").strip()
    entity = load_entity(firm_id, eid)
    if not entity: return jsonify({"error": "Entity not found"}), 404
    for poa in entity.get("poas", []):
        if poa["id"] == pid:
            poa["status"] = "revoked"; poa["revoked_date"] = datetime.date.today().isoformat()
            _add_history(entity, "governance", f"Power of attorney revoked: {poa['grantee_name']}",
                         recorded_by=get_user_id())
            break
    entity["updated_at"] = datetime.datetime.now().isoformat()
    save_entity(firm_id, eid, entity)
    return jsonify({"ok": True})

@app.route("/api/corp/compliance/add", methods=["POST"])
@login_required
@verify_csrf
def corp_add_compliance():
    firm_id = get_firm_id()
    d = request.get_json(force=True) or {}
    eid = d.get("entity_id", "").strip()
    entity = load_entity(firm_id, eid)
    if not entity: return jsonify({"error": "Entity not found"}), 404
    item = {
        "id": secrets.token_hex(6), "obligation": d.get("obligation", ""),
        "period": d.get("period", ""), "deadline": d.get("deadline", ""),
        "filed_date": d.get("filed_date", ""), "status": d.get("status", "pending"),
        "authority": d.get("authority", ""), "notes": d.get("notes", ""),
        "added_at": datetime.datetime.now().isoformat(),
    }
    entity.setdefault("compliance", []).append(item)
    entity["updated_at"] = datetime.datetime.now().isoformat()
    _add_history(entity, "compliance",
                 f"Compliance obligation added: {item['obligation']} ({item['period']})",
                 recorded_by=get_user_id())
    save_entity(firm_id, eid, entity)
    return jsonify({"ok": True, "id": item["id"]})

@app.route("/api/corp/compliance/update", methods=["POST"])
@login_required
@verify_csrf
def corp_update_compliance():
    firm_id = get_firm_id()
    d = request.get_json(force=True) or {}
    eid = d.get("entity_id", "").strip(); cid = d.get("item_id", "").strip()
    entity = load_entity(firm_id, eid)
    if not entity: return jsonify({"error": "Entity not found"}), 404
    for i, item in enumerate(entity.get("compliance", [])):
        if item["id"] == cid:
            for k, v in d.items():
                if k not in ("entity_id", "item_id"): entity["compliance"][i][k] = v
            if item.get("deadline") and not item.get("filed_date"):
                try:
                    if datetime.date.fromisoformat(item["deadline"]) < datetime.date.today():
                        entity["compliance"][i]["status"] = "overdue"
                except: pass
            break
    entity["updated_at"] = datetime.datetime.now().isoformat()
    _add_history(entity, "compliance", f"Compliance item updated (id: {cid})", recorded_by=get_user_id())
    save_entity(firm_id, eid, entity)
    return jsonify({"ok": True})

@app.route("/api/corp/history/add", methods=["POST"])
@login_required
@verify_csrf
def corp_add_history():
    firm_id = get_firm_id()
    d = request.get_json(force=True) or {}
    eid = d.get("entity_id", "").strip()
    entity = load_entity(firm_id, eid)
    if not entity: return jsonify({"error": "Entity not found"}), 404
    _add_history(entity, event_type=d.get("type", "other"),
                 description=d.get("description", ""), source=d.get("source", ""),
                 recorded_by=get_user_id())
    entity["updated_at"] = datetime.datetime.now().isoformat()
    save_entity(firm_id, eid, entity)
    return jsonify({"ok": True})

@app.route("/api/corp/ask", methods=["POST"])
@login_required
def corp_ask():
    firm_id = get_firm_id(); user_id = get_user_id()
    rate_key = f"{firm_id}_{user_id}"
    if not check_rate_limit(rate_key):
        return jsonify({"error": "Rate limit reached. Please wait."}), 429
    d        = request.get_json(force=True) or {}
    eid      = d.get("entity_id", "").strip()
    question = d.get("question", "").strip()
    if not question: return jsonify({"error": "Question required"}), 400
    entity  = load_entity(firm_id, eid) if eid else {}
    display = get_display_name()
    ctx_parts = []
    if entity:
        ctx_parts.append(f"Entity: {entity.get('name', '')} ({entity.get('legal_form', '')} · {entity.get('jurisdiction', '')})")
        ctx_parts.append(f"Registration: {entity.get('reg_number', '')} · VAT: {entity.get('vat_number', '')}")
        active_dirs = [dr for dr in entity.get("directors", []) if dr.get("status") == "active"]
        if active_dirs:
            dir_lines = [f"{dr.get('entity_name') or (dr.get('first_name', '') + ' ' + dr.get('last_name', '')).strip()} ({dr.get('role', '')}, mandate ends {dr.get('mandate_end', '')})"
                         for dr in active_dirs]
            ctx_parts.append("Active directors:\n" + "\n".join(dir_lines))
    entity_ctx = "\n".join(ctx_parts)
    system_extra = f"\n\nYou also have access to corporate entity data:\n\n{entity_ctx}\n\nWhen answering questions about this entity, use the data above and cite relevant Belgian legal provisions (WVV, KBO obligations)." if entity_ctx else ""
    try:
        client = get_client()
        resp   = client.messages.create(
            model="claude-sonnet-4-20250514", max_tokens=2000,
            system=get_system(display) + system_extra,
            messages=[{"role": "user", "content": question}]
        )
        answer = " ".join(b.text for b in resp.content if hasattr(b, "text") and b.text).strip()
        tokens = resp.usage.input_tokens + resp.usage.output_tokens
        log_usage(firm_id, user_id, "corp_ask", tokens, question[:40])
        return jsonify({"answer": answer})
    except ValueError as e: return jsonify({"error": str(e), "need_key": True}), 500
    except Exception as e:  return jsonify({"error": str(e)}), 500

def corp_docs_dir(firm_id: str, entity_id: str) -> Path:
    d = corp_path(firm_id) / entity_id / "docs"
    d.mkdir(parents=True, exist_ok=True)
    return d

def corp_docs_index_path(firm_id: str, entity_id: str) -> Path:
    return corp_path(firm_id) / entity_id / "docs_index.json"

def load_docs_index(firm_id: str, entity_id: str) -> dict:
    p = corp_docs_index_path(firm_id, entity_id)
    if p.exists():
        try: return json.loads(p.read_text(encoding="utf-8"))
        except: pass
    return {}

def save_docs_index(firm_id: str, entity_id: str, idx: dict):
    corp_docs_index_path(firm_id, entity_id).write_text(
        json.dumps(idx, ensure_ascii=False, indent=2), encoding="utf-8")

@app.route("/api/corp/docs", methods=["GET"])
@login_required
def corp_list_docs():
    firm_id = get_firm_id()
    eid = request.args.get("entity_id", "").strip()
    if not eid: return jsonify({"error": "entity_id required"}), 400
    idx  = load_docs_index(firm_id, eid)
    docs = sorted(idx.values(), key=lambda x: x.get("uploaded_at", ""), reverse=True)
    return jsonify({"docs": docs})

@app.route("/api/corp/doc/upload", methods=["POST"])
@login_required
def corp_upload_doc():
    firm_id = get_firm_id(); user_id = get_user_id()
    eid      = request.form.get("entity_id", "").strip()
    name     = (request.form.get("name") or "").strip()
    category = (request.form.get("category") or "other").strip()
    doc_date = (request.form.get("doc_date") or "").strip()
    notes    = (request.form.get("notes") or "").strip()
    file     = request.files.get("file")
    if not eid or not name or not file: return jsonify({"error": "entity_id, name and file required"}), 400
    entity = load_entity(firm_id, eid)
    if not entity: return jsonify({"error": "Entity not found"}), 404
    doc_id  = secrets.token_hex(8)
    safe_fn = re.sub(r'[^\w\s\-.]', '', file.filename or "file")[:80]
    dest    = corp_docs_dir(firm_id, eid) / f"{doc_id}_{safe_fn}"
    file.save(str(dest))
    try:
        file.seek(0)
        text = extract_bytes(file.read(), file.filename)
        if text:
            (corp_docs_dir(firm_id, eid) / f"{doc_id}.txt").write_text(text, encoding="utf-8")
    except: pass
    idx = load_docs_index(firm_id, eid)
    idx[doc_id] = {"id": doc_id, "name": name, "filename": safe_fn, "category": category,
                   "doc_date": doc_date, "notes": notes, "uploaded_by": user_id,
                   "uploaded_at": datetime.datetime.now().isoformat(), "file_path": str(dest)}
    save_docs_index(firm_id, eid, idx)
    entity = load_entity(firm_id, eid)
    if entity:
        _add_history(entity, "document", f"Document uploaded: {name} [{category}]",
                     source=safe_fn, recorded_by=user_id)
        entity["updated_at"] = datetime.datetime.now().isoformat()
        save_entity(firm_id, eid, entity)
    log_usage(firm_id, user_id, "corp_doc_upload", 0, f"{name[:40]} [{eid[:8]}]")
    return jsonify({"ok": True, "id": doc_id})

@app.route("/api/corp/doc/delete", methods=["POST"])
@login_required
@verify_csrf
def corp_delete_doc():
    firm_id = get_firm_id()
    d      = request.get_json(force=True) or {}
    eid    = d.get("entity_id", "").strip(); doc_id = d.get("doc_id", "").strip()
    if not eid or not doc_id: return jsonify({"error": "entity_id and doc_id required"}), 400
    idx = load_docs_index(firm_id, eid)
    entry = idx.pop(doc_id, None)
    if entry:
        for p in [entry.get("file_path"), str(corp_docs_dir(firm_id, eid) / f"{doc_id}.txt")]:
            if p:
                try: Path(p).unlink(missing_ok=True)
                except: pass
        save_docs_index(firm_id, eid, idx)
    return jsonify({"ok": True})

# ══════════════════════════════════════════════════════════════
# DOCUMENTS MODULE
# ══════════════════════════════════════════════════════════════

def docs_user_path(firm_id: str, user_id: str) -> Path:
    p = firm_path(firm_id) / "docs" / user_id
    for sub in ["history", "templates", "obligations", "anonymised"]:
        (p / sub).mkdir(parents=True, exist_ok=True)
    return p

def docs_load_json(path: Path) -> dict:
    try: return json.loads(path.read_text(encoding="utf-8"))
    except: return {}

def docs_save_json(path: Path, data: dict):
    path.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding="utf-8")

def docs_list_dir(path: Path) -> list:
    items = []
    for f in sorted(path.glob("*.json"), key=lambda x: x.stat().st_mtime, reverse=True):
        try: items.append(json.loads(f.read_text(encoding="utf-8")))
        except: continue
    return items

def docs_save_history(firm_id: str, user_id: str, module: str, filename: str,
                      result: str, meta: dict = None) -> str:
    item_id = str(uuid.uuid4())[:8]
    base = docs_user_path(firm_id, user_id) / "history" / f"{item_id}.json"
    docs_save_json(base, {
        "id": item_id, "module": module, "filename": filename,
        "result_preview": result[:300], "result": result,
        "meta": meta or {}, "created_at": datetime.datetime.utcnow().isoformat()
    })
    return item_id

@app.route("/api/docs/review", methods=["POST"])
@login_required
@verify_csrf
def docs_review():
    firm_id = get_firm_id(); user_id = get_user_id()
    rate_key = f"{firm_id}_{user_id}"
    if not check_rate_limit(rate_key): return jsonify({"error": "Rate limit reached."}), 429
    file = request.files.get("file")
    if not file: return jsonify({"error": "No file uploaded"}), 400
    focus       = request.form.get("focus", "General legal review")
    playbook    = request.form.get("playbook", "")
    perspective = request.form.get("perspective", "Neutral")
    audience    = request.form.get("audience", "Myself")
    extra       = request.form.get("extra", "")
    extracted = extract_bytes_with_meta(file.read(), file.filename)
    text = extracted["text"]
    if not text: return jsonify({"error": "Could not extract text from document.", "ocr_needed": True}), 400
    ctx = get_context(firm_id, user_id, focus + " " + file.filename)
    ctx_str = ("\n\nRelevant knowledge base references:\n\n" + "\n---\n".join(ctx[:2])) if ctx else ""
    audience_instruction = {
        "Myself":      "Write for a lawyer. Use legal terminology freely. Be direct and complete.",
        "Board":       "Write for non-lawyer board members. Executive summary first. Avoid jargon.",
        "Management":  "Write for senior management. Practical implications, business risk language.",
        "Other party": "Write diplomatically. Highlight mutual benefits.",
        "File record": "Write formally for the file. Complete, precise, citation-heavy."
    }.get(audience, "Write for a lawyer.")
    prompt = f"""Review this legal document and return a structured analysis.

Document: {file.filename}
Review focus: {focus}
Perspective: {perspective}
{f"Playbook to check against: {playbook}" if playbook else ""}
{f"Additional instructions: {extra}" if extra else ""}
{audience_instruction}
{ctx_str}

Document text:
{text[:9000]}

Return your analysis in this exact structure:

## Summary
[3-5 sentence summary]

## Findings

### 🔴 HIGH — Must fix
[For each: **Clause/Article** | **Issue** | **Recommended fix**]

### 🟡 MEDIUM — Should address
[For each: **Clause/Article** | **Issue** | **Recommended fix**]

### 🟢 LOW — Minor improvements
[For each: **Clause/Article** | **Issue** | **Suggested improvement**]

## Obligations extracted
[List every obligation, deadline or recurring requirement]
- **[Party]**: [obligation] — [deadline or trigger]

## Overall recommendation
[2-3 sentences: sign/negotiate/reject + key conditions]

**Sources cited:** [articles, regulations, cases referenced]"""
    display = get_display_name()
    answer, tokens, err = call_claude(display, prompt, docs_system(display))
    if err: return jsonify(err), 500
    obligations = []
    in_obligations = False
    for line in answer.split("\n"):
        if "## Obligations" in line: in_obligations = True; continue
        if line.startswith("## ") and in_obligations: break
        if in_obligations and line.strip().startswith("- "):
            obligations.append({"description": line.strip()[2:], "source_doc": file.filename,
                                 "extracted_at": datetime.datetime.utcnow().isoformat()})
    if obligations:
        obs_id = str(uuid.uuid4())[:8]
        docs_save_json(docs_user_path(firm_id, user_id) / "obligations" / f"{obs_id}.json", {
            "id": obs_id, "filename": file.filename, "obligations": obligations,
            "created_at": datetime.datetime.utcnow().isoformat()
        })
    history_id = docs_save_history(firm_id, user_id, "review", file.filename, answer,
                                   {"focus": focus, "perspective": perspective,
                                    "audience": audience, "ocr_needed": extracted["ocr_needed"]})
    log_usage(firm_id, user_id, "docs_review", tokens, file.filename[:40])
    return jsonify({"result": answer, "obligations": obligations, "filename": file.filename,
                    "ocr_needed": extracted["ocr_needed"], "pages": extracted["pages"],
                    "history_id": history_id})

@app.route("/api/docs/compare", methods=["POST"])
@login_required
@verify_csrf
def docs_compare():
    firm_id = get_firm_id(); user_id = get_user_id()
    if not check_rate_limit(f"{firm_id}_{user_id}"): return jsonify({"error": "Rate limit reached."}), 429
    file = request.files.get("file")
    if not file: return jsonify({"error": "No file uploaded"}), 400
    mode     = request.form.get("mode", "draft")
    focus    = request.form.get("focus", "")
    playbook = request.form.get("playbook", "")
    extra    = request.form.get("extra", "")
    extracted = extract_bytes_with_meta(file.read(), file.filename)
    text = extracted["text"]
    if not text: return jsonify({"error": "Could not extract text from document."}), 400
    display = get_display_name()
    if mode == "draft":
        file2 = request.files.get("file2")
        if not file2: return jsonify({"error": "Second file required"}), 400
        ext2 = extract_bytes_with_meta(file2.read(), file2.filename)
        ref_label = f"Reference draft: {file2.filename}"; ref_text = ext2["text"][:4500]
        mode_instruction = "Compare clause by clause between the two drafts."
    elif mode == "playbook":
        if not playbook: return jsonify({"error": "Playbook name required"}), 400
        ctx = get_context(firm_id, user_id, playbook)
        ref_label = f"Playbook: {playbook}"
        ref_text  = "\n".join(ctx[:3]) if ctx else f"[{playbook} — apply standard market positions]"
        mode_instruction = "Check whether each clause satisfies the playbook requirements."
    elif mode == "contracts":
        ctx = get_context(firm_id, user_id, focus or file.filename)
        ref_label = "Existing signed contracts (knowledge base)"
        ref_text  = "\n---\n".join(ctx[:3]) if ctx else "[No matching contracts found]"
        mode_instruction = "Compare key commercial terms against the precedents."
    else:
        ref_label = "Market standard positions"
        ref_text  = "[Apply your knowledge of market standard terms for this document type]"
        mode_instruction = "Compare each clause against market standard."
    prompt = f"""Compare this document against a reference.

Document under review: {file.filename}
{ref_label}
{f"Focus areas: {focus}" if focus else ""}
{mode_instruction}

Document text:
{text[:4500]}

Reference:
{ref_text}

Return your analysis in this exact structure:

## Comparison summary
[3-4 sentences]

## Clause-by-clause comparison

| Clause | Your document | Reference | Status | Risk |
|--------|--------------|-----------|--------|------|

## Key deviations — negotiation priorities

### Must push back on
### Should negotiate
### Accept or minor

## Overall position

**Sources cited:**"""
    answer, tokens, err = call_claude(display, prompt, docs_system(display))
    if err: return jsonify(err), 500
    history_id = docs_save_history(firm_id, user_id, "compare", file.filename, answer,
                                   {"mode": mode, "playbook": playbook})
    log_usage(firm_id, user_id, "docs_compare", tokens, file.filename[:40])
    return jsonify({"result": answer, "filename": file.filename, "mode": mode,
                    "ocr_needed": extracted["ocr_needed"], "history_id": history_id})

@app.route("/api/docs/draft", methods=["POST"])
@login_required
@verify_csrf
def docs_draft():
    firm_id = get_firm_id(); user_id = get_user_id()
    if not check_rate_limit(f"{firm_id}_{user_id}"): return jsonify({"error": "Rate limit reached."}), 429
    display = get_display_name()
    if request.content_type and "multipart" in request.content_type:
        d = request.form
        file = request.files.get("file")
        existing_text = extract_bytes_with_meta(file.read(), file.filename)["text"][:4000] if file else ""
    else:
        d = request.get_json(force=True) or {}
        existing_text = d.get("existing_text", "")
    mode          = d.get("mode", "new")
    doc_type      = d.get("doc_type", "contract clause")
    clause_desc   = d.get("clause_description", "")
    governing_law = d.get("governing_law", "Belgian law")
    perspective   = d.get("perspective", "Neutral")
    jurisdiction  = d.get("jurisdiction", "Belgium")
    instructions  = d.get("instructions", "")
    audience      = d.get("audience", "Myself")
    template_id   = d.get("template_id", "")
    template_text = ""
    if template_id:
        tpath = docs_user_path(firm_id, user_id) / "templates" / f"{template_id}.json"
        if tpath.exists():
            template_text = docs_load_json(tpath).get("content", "")
    ctx = get_context(firm_id, user_id, f"{doc_type} {clause_desc} {governing_law}")
    ctx_str = ("\n\nRelevant precedents:\n\n" + "\n---\n".join(ctx[:2])) if ctx else ""
    if mode == "new":
        prompt = f"""Draft a {doc_type}.

Description: {clause_desc}
Governing law: {governing_law}
Jurisdiction: {jurisdiction}
Perspective: {perspective}
{f"Instructions: {instructions}" if instructions else ""}
{f"Base on template:{chr(10)}{template_text}" if template_text else ""}
{ctx_str}

Requirements: Number all articles. Define capitalised terms. Cite legal basis. Flag items needing verification as [VERIFY: reason].

## Mickey notes
[Bullet list of items flagged [VERIFY]]"""
    elif mode == "improve":
        if not existing_text: return jsonify({"error": "Existing text required"}), 400
        prompt = f"""Improve this {doc_type}.

Perspective: {perspective} | Governing law: {governing_law}
{f"Instructions: {instructions}" if instructions else ""}
{ctx_str}

Original:
{existing_text}

Provide: 1) Redlined version (~~strikethrough~~ deletions, **bold** additions) 2) Clean final version 3) Explanation of changes

## Mickey notes
[Items requiring verification]"""
    else:
        if not existing_text: return jsonify({"error": "Existing clause required"}), 400
        prompt = f"""Generate a counter-proposal.

Our perspective: {perspective} | Governing law: {governing_law}
{f"Instructions: {instructions}" if instructions else ""}
{ctx_str}

Their clause:
{existing_text}

## Analysis of their position
## Our counter-proposal
## Negotiation notes
## Mickey notes"""
    answer, tokens, err = call_claude(display, prompt, docs_system(display), max_tokens=4000)
    if err: return jsonify(err), 500
    mickey_notes = []
    in_notes = False
    for line in answer.split("\n"):
        if "## Mickey notes" in line: in_notes = True; continue
        if line.startswith("## ") and in_notes: break
        if in_notes and line.strip().startswith("- "): mickey_notes.append(line.strip()[2:])
    filename = d.get("filename", f"{doc_type}_{mode}.txt") if isinstance(d, dict) else f"{doc_type}_{mode}.txt"
    history_id = docs_save_history(firm_id, user_id, "draft", filename, answer,
                                   {"mode": mode, "doc_type": doc_type, "governing_law": governing_law})
    log_usage(firm_id, user_id, "docs_draft", tokens, f"{mode}:{clause_desc[:30]}")
    return jsonify({"result": answer, "mode": mode, "mickey_notes": mickey_notes, "history_id": history_id})

@app.route("/api/docs/summarise", methods=["POST"])
@login_required
@verify_csrf
def docs_summarise():
    firm_id = get_firm_id(); user_id = get_user_id()
    if not check_rate_limit(f"{firm_id}_{user_id}"): return jsonify({"error": "Rate limit reached."}), 429
    file = request.files.get("file")
    if not file: return jsonify({"error": "No file uploaded"}), 400
    audience      = request.form.get("audience", "Myself")
    focus_areas   = request.form.get("focus_areas", "")
    output_format = request.form.get("output_format", "structured")
    extra         = request.form.get("extra", "")
    extracted = extract_bytes_with_meta(file.read(), file.filename)
    text = extracted["text"]
    if not text: return jsonify({"error": "Could not extract text."}), 400
    display = get_display_name()
    audience_formats = {
        "Myself":      "Detailed legal summary. Include all material provisions, conditions, and risks.",
        "Board":       "Executive summary for board. Lead with recommendation. Plain language. Max 400 words.",
        "Management":  "Operational summary. Focus on obligations, deadlines, and action items.",
        "Other party": "Neutral factual summary. Avoid adversarial framing.",
        "File record": "Comprehensive file note. Complete coverage. Formal language."
    }
    format_instructions = {
        "structured": "Use headers: Summary / Parties / Key terms / Obligations & deadlines / Risks / Recommendation",
        "executive":  "Single-page brief: What it is (2 sentences) / Key points (5 bullets) / Action required",
        "bullet":     "Structured bullet points only. Group by topic.",
        "table":      "Two-column table: Provision | Summary"
    }
    prompt = f"""Summarise this legal document.

Document: {file.filename}
Audience: {audience}
{f"Focus on: {focus_areas}" if focus_areas else ""}
{f"Instructions: {extra}" if extra else ""}

{audience_formats.get(audience, audience_formats["Myself"])}
Format: {format_instructions.get(output_format, format_instructions["structured"])}

Document text:
{text[:9000]}

After the summary add:
METADATA | Parties: [list] | Governing law: [law] | Key dates: [dates] | Document type: [type]"""
    answer, tokens, err = call_claude(display, prompt, docs_system(display))
    if err: return jsonify(err), 500
    parties, governing_law_found, doc_type_found = [], "", ""
    for line in answer.split("\n"):
        if line.startswith("METADATA |"):
            for part in line.split("|"):
                p = part.strip()
                if p.startswith("Parties:"): parties = [x.strip() for x in p[8:].split(",") if x.strip()]
                elif p.startswith("Governing law:"): governing_law_found = p[14:].strip()
                elif p.startswith("Document type:"): doc_type_found = p[14:].strip()
            answer = answer.replace(line, "").strip()
            break
    history_id = docs_save_history(firm_id, user_id, "summarise", file.filename, answer,
                                   {"audience": audience, "output_format": output_format,
                                    "parties": parties, "governing_law": governing_law_found})
    log_usage(firm_id, user_id, "docs_summarise", tokens, file.filename[:40])
    return jsonify({"result": answer, "parties": parties, "governing_law": governing_law_found,
                    "doc_type": doc_type_found, "filename": file.filename,
                    "ocr_needed": extracted["ocr_needed"], "pages": extracted["pages"],
                    "history_id": history_id})

@app.route("/api/docs/translate", methods=["POST"])
@login_required
@verify_csrf
def docs_translate():
    firm_id = get_firm_id(); user_id = get_user_id()
    if not check_rate_limit(f"{firm_id}_{user_id}"): return jsonify({"error": "Rate limit reached."}), 429
    file = request.files.get("file")
    if not file: return jsonify({"error": "No file uploaded"}), 400
    src_lang = request.form.get("src_lang", "Dutch (NL)")
    tgt_lang = request.form.get("tgt_lang", "English (EN)")
    style    = request.form.get("style", "Legal / formal")
    extra    = request.form.get("extra", "")
    extracted = extract_bytes_with_meta(file.read(), file.filename)
    text = extracted["text"]
    if not text: return jsonify({"error": "Could not extract text."}), 400
    display = get_display_name()
    style_notes = {
        "Legal / formal": "Preserve all legal terminology. Keep article numbering. Do not simplify.",
        "Plain":          "Translate accurately in clear, accessible language.",
        "Simplified":     "Translate and simplify. Write as if explaining to a non-lawyer."
    }
    prompt = f"""Translate from {src_lang} to {tgt_lang}.

Style: {style} — {style_notes.get(style, style_notes["Legal / formal"])}
{f"Instructions: {extra}" if extra else ""}

Rules: Preserve structure, numbering, and article references exactly. Translation only.

Document:
{text[:8000]}

After translation add:
## Translator's notes
- List terms kept in original language and why
- List material ambiguities"""
    answer, tokens, err = call_claude(display, prompt, docs_system(display), max_tokens=5000)
    if err: return jsonify(err), 500
    untranslatable = []
    in_notes = False
    for line in answer.split("\n"):
        if "## Translator" in line: in_notes = True; continue
        if line.startswith("## ") and in_notes: break
        if in_notes and line.strip().startswith("- "): untranslatable.append(line.strip()[2:])
    history_id = docs_save_history(firm_id, user_id, "translate", file.filename, answer,
                                   {"src_lang": src_lang, "tgt_lang": tgt_lang, "style": style})
    log_usage(firm_id, user_id, "docs_translate", tokens, file.filename[:40])
    return jsonify({"result": answer, "untranslatable": untranslatable, "filename": file.filename,
                    "src_lang": src_lang, "tgt_lang": tgt_lang,
                    "ocr_needed": extracted["ocr_needed"], "history_id": history_id})

@app.route("/api/docs/anonymise", methods=["POST"])
@login_required
@verify_csrf
def docs_anonymise():
    firm_id = get_firm_id(); user_id = get_user_id()
    if not check_rate_limit(f"{firm_id}_{user_id}"): return jsonify({"error": "Rate limit reached."}), 429
    file = request.files.get("file")
    if not file: return jsonify({"error": "No file uploaded"}), 400
    preset        = request.form.get("preset", "")
    custom_fields = request.form.get("custom_fields", "[]")
    include_map   = request.form.get("include_map", "true").lower() == "true"
    try: custom = json.loads(custom_fields)
    except: custom = []
    extracted = extract_bytes_with_meta(file.read(), file.filename)
    text = extracted["text"]
    if not text: return jsonify({"error": "Could not extract text."}), 400
    display = get_display_name()
    preset_instructions = {
        "commercial": "Also redact: exact prices, product names, delivery locations, payment details.",
        "manda":      "Also redact: target company name, financial advisors, valuation figures, deal structure.",
        "employment": "Also redact: salary figures, employee IDs, performance ratings.",
        "litigation": "Also redact: case reference numbers, settlement amounts, expert names."
    }
    custom_instruction = ""
    if custom:
        custom_instruction = "\n\nCustom replacements:\n" + \
            "\n".join(f'- Replace "{c["find"]}" with "{c["replace"]}"'
                      for c in custom if c.get("find") and c.get("replace"))
    prompt = f"""Anonymise this legal document.

Document: {file.filename}
{f"Domain preset: {preset_instructions.get(preset, '')}" if preset else ""}
{custom_instruction}

Standard redactions:
- Party names → [PARTY A], [PARTY B], etc. (consistent throughout)
- Addresses → [ADDRESS 1], [ADDRESS 2] etc.
- Registration/KBO numbers → [REG NUMBER]
- Email addresses → [EMAIL]
- IBAN/bank accounts → [BANK ACCOUNT]
- Phone numbers → [PHONE]
- Signatures → [SIGNATURE]

Document:
{text[:8000]}

Return:

## Anonymised document
[Full anonymised text]

## Redaction map
REDACTION | Original: [value] | Replaced with: [placeholder] | Category: [category] | Count: [n]"""
    answer, tokens, err = call_claude(display, prompt, docs_system(display), max_tokens=6000)
    if err: return jsonify(err), 500
    anon_text = ""; redaction_map = []; in_doc = False; in_map = False
    for line in answer.split("\n"):
        if "## Anonymised document" in line: in_doc, in_map = True, False; continue
        if "## Redaction map" in line: in_doc, in_map = False, True; continue
        if line.startswith("## ") and (in_doc or in_map): in_doc = in_map = False
        if in_doc: anon_text += line + "\n"
        elif in_map and line.startswith("REDACTION |"):
            parts = line.split("|"); entry = {}
            for part in parts[1:]:
                p = part.strip()
                if p.startswith("Original:"): entry["original"] = p[9:].strip()
                elif p.startswith("Replaced with:"): entry["replacement"] = p[14:].strip()
                elif p.startswith("Category:"): entry["category"] = p[9:].strip()
                elif p.startswith("Count:"):
                    try: entry["count"] = int(p[6:].strip())
                    except: entry["count"] = 1
            if entry.get("original"): redaction_map.append(entry)
    anon_text = anon_text.strip() or answer
    for c in custom:
        if c.get("find") and c.get("replace"):
            count = anon_text.count(c["find"])
            if count:
                anon_text = anon_text.replace(c["find"], c["replace"])
                redaction_map.append({"original": c["find"], "replacement": c["replace"],
                                       "category": "custom", "count": count})
    anon_id = str(uuid.uuid4())[:8]
    anon_dir = docs_user_path(firm_id, user_id) / "anonymised" / anon_id
    anon_dir.mkdir(parents=True, exist_ok=True)
    (anon_dir / "anonymised.txt").write_text(anon_text, encoding="utf-8")
    if include_map:
        docs_save_json(anon_dir / "redaction_map.json", {"filename": file.filename, "map": redaction_map})
    total_redactions = sum(e.get("count", 1) for e in redaction_map)
    history_id = docs_save_history(firm_id, user_id, "anonymise", file.filename, anon_text,
                                   {"preset": preset, "total_redactions": total_redactions, "anon_id": anon_id})
    log_usage(firm_id, user_id, "docs_anonymise", tokens, file.filename[:40])
    return jsonify({"result": anon_text, "redaction_map": redaction_map if include_map else [],
                    "stats": {"total_redactions": total_redactions,
                               "categories_used": list({e.get("category", "other") for e in redaction_map})},
                    "filename": file.filename, "anon_id": anon_id, "history_id": history_id})

@app.route("/api/docs/history", methods=["GET"])
@login_required
def docs_history():
    firm_id = get_firm_id(); user_id = get_user_id()
    module   = request.args.get("module", "")
    limit    = min(int(request.args.get("limit", "50")), 200)
    hist_dir = docs_user_path(firm_id, user_id) / "history"
    items    = docs_list_dir(hist_dir)
    if module: items = [i for i in items if i.get("module") == module]
    previews = [{"id": i.get("id"), "module": i.get("module"), "filename": i.get("filename"),
                 "result_preview": i.get("result_preview", "")[:200],
                 "meta": i.get("meta", {}), "created_at": i.get("created_at")}
                for i in items[:limit]]
    return jsonify({"items": previews, "total": len(items)})

@app.route("/api/docs/history/<item_id>", methods=["GET"])
@login_required
def docs_history_item(item_id):
    firm_id = get_firm_id(); user_id = get_user_id()
    if not re.match(r'^[a-zA-Z0-9\-]+$', item_id): return jsonify({"error": "Invalid id"}), 400
    path = docs_user_path(firm_id, user_id) / "history" / f"{item_id}.json"
    if not path.exists(): return jsonify({"error": "Not found"}), 404
    return jsonify(docs_load_json(path))

@app.route("/api/docs/history/<item_id>", methods=["DELETE"])
@login_required
@verify_csrf
def docs_history_delete(item_id):
    firm_id = get_firm_id(); user_id = get_user_id()
    if not re.match(r'^[a-zA-Z0-9\-]+$', item_id): return jsonify({"error": "Invalid id"}), 400
    path = docs_user_path(firm_id, user_id) / "history" / f"{item_id}.json"
    if not path.exists(): return jsonify({"error": "Not found"}), 404
    path.unlink()
    return jsonify({"ok": True})

@app.route("/api/docs/templates", methods=["GET"])
@login_required
def docs_templates_list():
    firm_id = get_firm_id(); user_id = get_user_id()
    doc_type = request.args.get("doc_type", "")
    tmpl_dir = docs_user_path(firm_id, user_id) / "templates"
    items    = docs_list_dir(tmpl_dir)
    if doc_type: items = [i for i in items if i.get("doc_type", "").lower() == doc_type.lower()]
    previews = [{"id": i.get("id"), "name": i.get("name"), "doc_type": i.get("doc_type"),
                 "governing_law": i.get("governing_law"), "tags": i.get("tags", []),
                 "content_preview": (i.get("content", "")[:150] + "…") if i.get("content") else "",
                 "created_at": i.get("created_at"), "updated_at": i.get("updated_at")}
                for i in items]
    return jsonify({"templates": previews})

@app.route("/api/docs/templates", methods=["POST"])
@login_required
@verify_csrf
def docs_templates_save():
    firm_id = get_firm_id(); user_id = get_user_id()
    d    = request.get_json(force=True) or {}
    name = d.get("name", "").strip()
    if not name: return jsonify({"error": "Template name required"}), 400
    tmpl_id = d.get("id", str(uuid.uuid4())[:8])
    now     = datetime.datetime.utcnow().isoformat()
    path    = docs_user_path(firm_id, user_id) / "templates" / f"{tmpl_id}.json"
    existing = docs_load_json(path) if path.exists() else {}
    template = {
        "id": tmpl_id, "name": name,
        "doc_type":      d.get("doc_type", existing.get("doc_type", "")),
        "governing_law": d.get("governing_law", existing.get("governing_law", "Belgian law")),
        "content":       d.get("content", existing.get("content", "")),
        "tags":          d.get("tags", existing.get("tags", [])),
        "created_at":    existing.get("created_at", now),
        "updated_at":    now
    }
    docs_save_json(path, template)
    return jsonify({"ok": True, "id": tmpl_id, "template": template})

@app.route("/api/docs/template/<tmpl_id>", methods=["GET"])
@login_required
def docs_template_get(tmpl_id):
    firm_id = get_firm_id(); user_id = get_user_id()
    if not re.match(r'^[a-zA-Z0-9\-]+$', tmpl_id): return jsonify({"error": "Invalid id"}), 400
    path = docs_user_path(firm_id, user_id) / "templates" / f"{tmpl_id}.json"
    if not path.exists(): return jsonify({"error": "Not found"}), 404
    return jsonify(docs_load_json(path))

@app.route("/api/docs/template/<tmpl_id>", methods=["DELETE"])
@login_required
@verify_csrf
def docs_template_delete(tmpl_id):
    firm_id = get_firm_id(); user_id = get_user_id()
    if not re.match(r'^[a-zA-Z0-9\-]+$', tmpl_id): return jsonify({"error": "Invalid id"}), 400
    path = docs_user_path(firm_id, user_id) / "templates" / f"{tmpl_id}.json"
    if not path.exists(): return jsonify({"error": "Not found"}), 404
    path.unlink()
    return jsonify({"ok": True})

@app.route("/api/docs/obligations", methods=["GET"])
@login_required
def docs_obligations():
    firm_id = get_firm_id(); user_id = get_user_id()
    limit   = min(int(request.args.get("limit", "100")), 500)
    obs_dir = docs_user_path(firm_id, user_id) / "obligations"
    all_obs = []
    for item in docs_list_dir(obs_dir)[:limit]:
        for ob in item.get("obligations", []):
            all_obs.append({**ob, "source_doc": item.get("filename", ""),
                            "extracted_at": item.get("created_at", "")})
    return jsonify({"obligations": all_obs, "total": len(all_obs)})

# ── Run ────────────────────────────────────────────────────────

if __name__ == "__main__":
    host = os.environ.get("MICKEY_HOST", "0.0.0.0")
    port = int(os.environ.get("MICKEY_PORT", "5000"))
    print(f"\n  Mickey — Legal Intelligence Platform")
    print(f"  Data: {DATA_PATH}")
    print(f"  Rate limit: {RATE_LIMIT_CALLS_PER_HOUR} calls/user/hour")
    try:
        from waitress import serve
        print(f"  Running at http://{host}:{port} (Waitress)\n")
        serve(app, host=host, port=port, threads=8)
    except ImportError:
        print(f"  Running at http://{host}:{port} (Flask dev server)\n")
        app.run(debug=False, port=port, host=host)
